{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kimso\\anaconda3\\envs\\ailab\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "from datasets import Dataset\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_data_path = '../datasets/gpt_story.json'\n",
    "\n",
    "with open(json_data_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 4, 'content': \"산길을 걷던 남자는 우연히 떨어진 그림엽서를 발견했다. 그림 속에는 자신이 어릴 적 갔던 바다가 그려져 있었다. 뒷면에는 낯익은 필체로 '다시 만나자'라는 문구가 적혀 있었다. 누군가의 초대 같았다.\"}\n"
     ]
    }
   ],
   "source": [
    "print(data[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 데이터 로드\n",
    "train = pd.read_csv('../datasets/sentiment_conversation/train.csv')\n",
    "val = pd.read_csv('../datasets/sentiment_conversation/val.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentiment\n",
      "4    26301\n",
      "2    26000\n",
      "3    25957\n",
      "1    25814\n",
      "5    24936\n",
      "0    16947\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train[\"sentiment\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. KLUE/roberta-base 토크나이저 적용\n",
    "model_name = \"klue/roberta-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True, max_length=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 3000/3000 [00:00<00:00, 18925.86 examples/s]\n",
      "Map: 100%|██████████| 500/500 [00:00<00:00, 18400.59 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# 3. Hugging Face Dataset 변환\n",
    "train_dataset = Dataset.from_pandas(train)\n",
    "val_dataset = Dataset.from_pandas(val)\n",
    "\n",
    "# 추가\n",
    "train_dataset = train_dataset.select(range(3000))\n",
    "val_dataset = val_dataset.select(range(500))\n",
    "# 나중에 삭제 필요\n",
    "\n",
    "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "val_dataset = val_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "train_dataset = train_dataset.remove_columns([\"text\"])\n",
    "val_dataset = val_dataset.remove_columns([\"text\"])\n",
    "\n",
    "train_dataset = train_dataset.rename_column(\"sentiment\", \"labels\")\n",
    "val_dataset = val_dataset.rename_column(\"sentiment\", \"labels\")\n",
    "\n",
    "train_dataset.set_format(\"torch\")\n",
    "val_dataset.set_format(\"torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kimso\\anaconda3\\envs\\ailab\\lib\\site-packages\\transformers\\modeling_utils.py:1211: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(resolved_archive_file, map_location=\"cpu\")\n",
      "Some weights of the model checkpoint at klue/roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.decoder.bias', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RobertaForSequenceClassification(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(32000, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): RobertaClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=6, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4. 모델 정의\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=len(train[\"sentiment\"].unique()))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. TrainingArguments 설정\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"/results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_dir=\"./logs\",\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=2,\n",
    "    load_best_model_at_end=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Trainer 정의 및 학습\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,  # 소규모 데이터셋 사용\n",
    "    eval_dataset=val_dataset,  # 소규모 검증 데이터 사용\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 3000\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 940\n",
      " 20%|██        | 188/940 [00:33<01:56,  6.45it/s]***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 16\n",
      "                                                 \n",
      " 20%|██        | 188/940 [00:34<01:56,  6.45it/s]Saving model checkpoint to /results\\checkpoint-188\n",
      "Configuration saved in /results\\checkpoint-188\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.1837528944015503, 'eval_runtime': 1.5255, 'eval_samples_per_second': 327.769, 'eval_steps_per_second': 20.977, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in /results\\checkpoint-188\\pytorch_model.bin\n",
      "Deleting older checkpoint [\\results\\checkpoint-376] due to args.save_total_limit\n",
      " 40%|████      | 376/940 [01:08<01:26,  6.54it/s]***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 16\n",
      "                                                 \n",
      " 40%|████      | 376/940 [01:10<01:26,  6.54it/s]Saving model checkpoint to /results\\checkpoint-376\n",
      "Configuration saved in /results\\checkpoint-376\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.1352373361587524, 'eval_runtime': 1.5327, 'eval_samples_per_second': 326.218, 'eval_steps_per_second': 20.878, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in /results\\checkpoint-376\\pytorch_model.bin\n",
      "Deleting older checkpoint [\\results\\checkpoint-564] due to args.save_total_limit\n",
      " 53%|█████▎    | 501/940 [01:33<01:19,  5.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0588, 'learning_rate': 2.340425531914894e-05, 'epoch': 2.66}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 564/940 [01:44<01:00,  6.26it/s]***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 16\n",
      "                                                 \n",
      " 60%|██████    | 564/940 [01:46<01:00,  6.26it/s]Saving model checkpoint to /results\\checkpoint-564\n",
      "Configuration saved in /results\\checkpoint-564\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.234623670578003, 'eval_runtime': 1.5605, 'eval_samples_per_second': 320.401, 'eval_steps_per_second': 20.506, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in /results\\checkpoint-564\\pytorch_model.bin\n",
      "Deleting older checkpoint [\\results\\checkpoint-188] due to args.save_total_limit\n",
      " 80%|████████  | 752/940 [02:20<00:29,  6.45it/s]***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 16\n",
      "                                                 \n",
      " 80%|████████  | 752/940 [02:22<00:29,  6.45it/s]Saving model checkpoint to /results\\checkpoint-752\n",
      "Configuration saved in /results\\checkpoint-752\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.4105887413024902, 'eval_runtime': 1.5478, 'eval_samples_per_second': 323.031, 'eval_steps_per_second': 20.674, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in /results\\checkpoint-752\\pytorch_model.bin\n",
      "Deleting older checkpoint [\\results\\checkpoint-564] due to args.save_total_limit\n",
      "100%|██████████| 940/940 [02:56<00:00,  6.32it/s]***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 16\n",
      "                                                 \n",
      "100%|██████████| 940/940 [02:58<00:00,  6.32it/s]Saving model checkpoint to /results\\checkpoint-940\n",
      "Configuration saved in /results\\checkpoint-940\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.4811369180679321, 'eval_runtime': 1.5584, 'eval_samples_per_second': 320.835, 'eval_steps_per_second': 20.533, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in /results\\checkpoint-940\\pytorch_model.bin\n",
      "Deleting older checkpoint [\\results\\checkpoint-752] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from /results\\checkpoint-376 (score: 1.1352373361587524).\n",
      "c:\\Users\\kimso\\anaconda3\\envs\\ailab\\lib\\site-packages\\transformers\\trainer.py:1364: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(best_model_path, map_location=\"cpu\")\n",
      "100%|██████████| 940/940 [02:59<00:00,  5.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 179.8574, 'train_samples_per_second': 83.399, 'train_steps_per_second': 5.226, 'train_loss': 0.766505415896152, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=940, training_loss=0.766505415896152, metrics={'train_runtime': 179.8574, 'train_samples_per_second': 83.399, 'train_steps_per_second': 5.226, 'train_loss': 0.766505415896152, 'epoch': 5.0})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaForSequenceClassification(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(32000, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): RobertaClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=6, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: 별이 가득한 하늘 아래, 소년은 잃어버린 물건을 찾기 위해 숲을 헤맸다. 한참을 걸은 끝에 반짝이는 물체를 발견했는데, 그것은 오래된 나침반이었다. 나침반을 손에 쥔 순간, 이상한 일이 벌어졌다. 화살표가 빛나며 소년을 새로운 모험으로 이끌었다.\n",
      "Scores: [[0.22582344710826874, 0.08359823375940323, 0.03415907174348831, 0.09653785079717636, 0.06759481132030487, 0.4922865331172943]]\n",
      "Predicted label: 5\n",
      "\n",
      "Text: 도시는 조용했다. 평소라면 차와 사람들이 가득했을 거리가 텅 비어 있었다. 한 소녀가 작은 강아지를 안고 거리를 걸으며 주변을 살폈다. 그러다 발견한 붉은 종이비행기. 비행기 안쪽에는 '희망은 어디에나 있다'라는 문구가 적혀 있었다.\n",
      "Scores: [[0.339579313993454, 0.3605920374393463, 0.0220583975315094, 0.06683194637298584, 0.0857134759426117, 0.12522482872009277]]\n",
      "Predicted label: 1\n",
      "\n",
      "Text: 작은 시골 마을의 우체국에는 매주 편지가 도착했다. 하지만 이상하게도 보낸 사람은 적혀 있지 않았다. 편지는 항상 누군가에게 따뜻한 위로와 희망을 전하는 내용이었다. 사람들은 궁금해했지만, 끝내 발신자는 밝혀지지 않았다.\n",
      "Scores: [[0.6719879508018494, 0.086091548204422, 0.018563617020845413, 0.06782062351703644, 0.047260452061891556, 0.10827581584453583]]\n",
      "Predicted label: 0\n",
      "\n",
      "Text: 산길을 걷던 남자는 우연히 떨어진 그림엽서를 발견했다. 그림 속에는 자신이 어릴 적 갔던 바다가 그려져 있었다. 뒷면에는 낯익은 필체로 '다시 만나자'라는 문구가 적혀 있었다. 누군가의 초대 같았다.\n",
      "Scores: [[0.4835893511772156, 0.09506925940513611, 0.021305669099092484, 0.09694784134626389, 0.04924400895833969, 0.2538437843322754]]\n",
      "Predicted label: 0\n",
      "\n",
      "Text: 한밤중에 잠에서 깬 소년은 창문 밖에서 들려오는 이상한 소리를 들었다. 밖을 내다보니 작은 고양이가 소리 내어 울고 있었다. 소년은 고양이를 집 안으로 데려왔고, 그날 이후 둘은 떨어질 수 없는 친구가 되었다.\n",
      "Scores: [[0.09589260071516037, 0.7830356359481812, 0.015178412199020386, 0.04794524610042572, 0.02938968688249588, 0.028558431193232536]]\n",
      "Predicted label: 1\n",
      "\n",
      "Text: 강가에서 낚시를 하던 노인은 물속에서 빛나는 병을 발견했다. 병 속에는 오래된 쪽지가 들어 있었는데, '이 병을 발견한 이는 행운을 얻을 것이다'라고 적혀 있었다. 그날부터 노인의 삶은 놀랍도록 변하기 시작했다.\n",
      "Scores: [[0.8060307502746582, 0.07867617160081863, 0.011419715359807014, 0.04651467874646187, 0.023657146841287613, 0.033701613545417786]]\n",
      "Predicted label: 0\n",
      "\n",
      "Text: 비 오는 날, 한 소녀는 학교로 가는 길에 낡은 우산을 발견했다. 우산에는 '행운의 우산'이라는 작은 메모가 붙어 있었다. 소녀는 우산을 쓰기 시작했고, 이상하게도 그날 이후 좋은 일이 계속해서 일어났다.\n",
      "Scores: [[0.9415281414985657, 0.01546073704957962, 0.003368210978806019, 0.020185627043247223, 0.007360134273767471, 0.012097146362066269]]\n",
      "Predicted label: 0\n",
      "\n",
      "Text: 숲속 깊은 곳에 있는 작은 오두막에는 매일 밤 불빛이 켜졌다. 마을 사람들은 그곳에 누군가가 산다는 소문을 들었지만, 아무도 그를 본 적이 없었다. 어느 날, 용기를 낸 한 소년이 오두막을 찾아갔고 놀라운 비밀을 발견했다.\n",
      "Scores: [[0.718015193939209, 0.09379760175943375, 0.015194090083241463, 0.08194639533758163, 0.04027465358376503, 0.05077207460999489]]\n",
      "Predicted label: 0\n",
      "\n",
      "Text: 늦은 밤, 정류장에서 버스를 기다리던 남자는 이상한 기운을 느꼈다. 누군가 자신을 지켜보는 것 같았다. 고개를 돌리자, 낡은 벤치 위에 오래된 사진이 놓여 있었다. 사진 속에는 그와 똑같이 생긴 사람이 서 있었다.\n",
      "Scores: [[0.04015381261706352, 0.035981763154268265, 0.023644810542464256, 0.06257135421037674, 0.04185338318347931, 0.7957948446273804]]\n",
      "Predicted label: 5\n",
      "\n",
      "Text: 한적한 해변에서 발견된 오래된 일기장은 누군가의 비밀로 가득 차 있었다. 글을 읽던 소녀는 일기 속 주인공과 자신의 삶이 이상하리만큼 닮아 있다는 것을 알게 되었다. 마치 자신을 위한 이야기처럼 느껴졌다.\n",
      "Scores: [[0.20576491951942444, 0.060344334691762924, 0.022648481652140617, 0.14551569521427155, 0.04182949662208557, 0.523897111415863]]\n",
      "Predicted label: 5\n",
      "\n",
      "Text: 노을이 지는 강가에서 한 남자가 낚시를 하고 있었다. 물속에서 무언가 빛나는 것을 발견한 그는 손을 뻗어 그것을 꺼냈다. 그것은 오래된 황금 반지였다. 반지에는 '영원한 사랑'이라는 글자가 새겨져 있었고, 그 후로 그의 삶은 놀라운 방향으로 흘러갔다.\n",
      "Scores: [[0.8397181630134583, 0.07527091354131699, 0.007042217534035444, 0.0370783805847168, 0.016287371516227722, 0.024603059515357018]]\n",
      "Predicted label: 0\n",
      "\n",
      "Text: 작은 도서관의 구석에서 낡은 책 한 권이 발견되었다. 책의 첫 페이지에는 '읽는 이에게 행운을'이라는 문구가 적혀 있었다. 책을 읽기 시작한 소녀는 매일 꿈속에서 책 속의 이야기를 경험하며 놀라운 모험을 시작했다.\n",
      "Scores: [[0.917550802230835, 0.02398151345551014, 0.004180969670414925, 0.02842646837234497, 0.009613282047212124, 0.016246993094682693]]\n",
      "Predicted label: 0\n",
      "\n",
      "Text: 도시의 오래된 골목길에는 늘 기타를 치는 한 소년이 있었다. 그는 누구도 모르는 곡을 연주했지만, 그 음악은 지나가는 사람들의 마음을 울렸다. 어느 날, 한 청중이 다가와 '이 곡은 어디서 배운 거니?'라고 묻자 소년은 '꿈에서 들었다'고 답했다.\n",
      "Scores: [[0.7366471886634827, 0.06981583684682846, 0.012414280325174332, 0.061204925179481506, 0.02797006629407406, 0.09194774925708771]]\n",
      "Predicted label: 0\n",
      "\n",
      "Text: 버려진 놀이터에서 놀던 아이들은 지하에 숨겨진 비밀 문을 발견했다. 문을 열자 거대한 미로가 나타났고, 아이들은 미로 속에서 환상적인 모험을 시작했다. 그곳에는 꿈에서만 보던 동물들과 마법의 세계가 기다리고 있었다.\n",
      "Scores: [[0.7803793549537659, 0.05695023015141487, 0.01391549315303564, 0.06363153457641602, 0.03556635230779648, 0.04955710843205452]]\n",
      "Predicted label: 0\n",
      "\n",
      "Text: 작은 카페의 메뉴판 뒤에는 오래된 편지가 숨겨져 있었다. 한 여성이 우연히 발견한 편지에는 '사랑하는 이에게'라는 제목과 함께 과거의 가슴 절절한 이야기가 담겨 있었다. 그녀는 편지의 주인을 찾아 나섰고, 놀라운 인연을 만나게 되었다.\n",
      "Scores: [[0.47046762704849243, 0.3305974304676056, 0.010956628248095512, 0.10871604830026627, 0.02136370725929737, 0.057898491621017456]]\n",
      "Predicted label: 0\n",
      "\n",
      "Text: 학교 뒷마당에서 놀던 소년은 땅에 묻힌 작은 상자를 발견했다. 상자 속에는 오래된 동전과 함께 '용기를 가지면 모든 것을 얻을 수 있다'는 글귀가 적힌 쪽지가 있었다. 소년은 이후 도전하는 삶을 살며 꿈을 이루기 시작했다.\n",
      "Scores: [[0.840430498123169, 0.054536450654268265, 0.008532500825822353, 0.046878933906555176, 0.019993461668491364, 0.02962818369269371]]\n",
      "Predicted label: 0\n",
      "\n",
      "Text: 한밤중에 잠에서 깬 한 남자는 창밖에 빛나는 별 하나가 점점 커지는 것을 보았다. 별은 그의 방으로 들어와 작은 구슬이 되었고, 구슬은 그에게 소원을 들어줄 수 있다고 말했다. 그는 인생의 가장 중요한 소원을 빌기로 결심했다.\n",
      "Scores: [[0.7173177599906921, 0.09547051787376404, 0.021770155057311058, 0.05874968692660332, 0.05529205873608589, 0.0513998419046402]]\n",
      "Predicted label: 0\n",
      "\n",
      "Text: 낯선 도시의 오래된 다리 위에서 한 소녀가 사진을 찍고 있었다. 사진 속에 나타난 희미한 그림자는 그녀가 잃어버린 친구를 닮아 있었다. 소녀는 진실을 찾기 위해 다리 아래 숨겨진 비밀을 조사하기 시작했다.\n",
      "Scores: [[0.1464584916830063, 0.13796241581439972, 0.03247583284974098, 0.10996930301189423, 0.10810133814811707, 0.4650326073169708]]\n",
      "Predicted label: 5\n",
      "\n",
      "Text: 가을의 어느 날, 낡은 나무 아래에서 한 청년이 오래된 손수건을 발견했다. 손수건에는 정성스럽게 수놓아진 이니셜과 함께 '기억의 조각'이라는 글자가 새겨져 있었다. 그는 손수건의 주인을 찾기 위해 여정을 떠났다.\n",
      "Scores: [[0.5951271653175354, 0.18925102055072784, 0.016927199438214302, 0.07435154169797897, 0.03786354511976242, 0.0864795669913292]]\n",
      "Predicted label: 0\n",
      "\n",
      "Text: 한 마을에는 전설이 있었다. 마을 중앙의 큰 나무에 걸린 종을 울리면 소원을 이룰 수 있다는 것이다. 어느 날, 한 아이가 용기를 내어 종을 울렸다. 하지만 종소리와 함께 나타난 것은 소원이 아닌 마을의 오래된 비밀이었다.\n",
      "Scores: [[0.5703499913215637, 0.2156122773885727, 0.020593905821442604, 0.09582904726266861, 0.053929246962070465, 0.04368548467755318]]\n",
      "Predicted label: 0\n",
      "\n",
      "Text: 밤하늘에 떠 있는 별들이 유난히 밝던 날, 한 소녀는 자신의 방 창문에서 이상한 빛을 발견했다. 빛은 그녀를 숲속 깊은 곳으로 인도했고, 거기서 오래된 나무문을 발견했다. 문을 열자 그녀는 자신이 잃어버렸던 기억 속으로 빨려 들어갔다.\n",
      "Scores: [[0.12169690430164337, 0.057328153401613235, 0.02649138681590557, 0.08946489542722702, 0.05688147991895676, 0.6481372117996216]]\n",
      "Predicted label: 5\n",
      "\n",
      "Text: 도시 한가운데에 있는 폐허가 된 극장에서 수상한 소리가 들린다는 소문이 돌았다. 한 남자가 이를 확인하러 갔고, 그곳에서 무대에 홀로 서 있는 신비로운 여인을 만났다. 그녀는 과거를 노래하며 남자의 숨겨진 진실을 드러냈다.\n",
      "Scores: [[0.3118654191493988, 0.1106184720993042, 0.02949826605618, 0.1409580409526825, 0.08026841282844543, 0.3267914354801178]]\n",
      "Predicted label: 5\n",
      "\n",
      "Text: 어느 한적한 해변가에서 한 어부가 조개껍데기 속에 갇힌 작은 인형을 발견했다. 인형은 마치 살아 있는 듯 정교했으며, 어부의 손이 닿자 따뜻해졌다. 그날 밤, 어부는 자신을 향한 감사의 목소리를 꿈속에서 들었다.\n",
      "Scores: [[0.9459743499755859, 0.02100597880780697, 0.0028093091677874327, 0.015793634578585625, 0.00559341860935092, 0.0088232746347785]]\n",
      "Predicted label: 0\n",
      "\n",
      "Text: 어느 날, 한 고등학생이 학교 도서관에서 아주 낡은 책을 발견했다. 그 책에는 학생이 읽는 순간 그의 미래가 적혀 나왔다. 하지만 몇 장을 넘길수록 그는 책의 내용을 바꿀 수 있는 선택지가 주어짐을 알게 되었다.\n",
      "Scores: [[0.2312309294939041, 0.2736014425754547, 0.031719110906124115, 0.11889515072107315, 0.13384854793548584, 0.21070484817028046]]\n",
      "Predicted label: 1\n",
      "\n",
      "Text: 마을 외곽의 오래된 우물은 전설적인 소원을 이룰 수 있는 장소로 알려져 있었다. 한 아이가 가족의 병을 치료하기 위해 동전을 던지고 소원을 빌었다. 그런데 우물에서 물이 아닌 금빛 물방울이 솟구치며 아이를 놀라게 했다.\n",
      "Scores: [[0.1609041690826416, 0.15987619757652283, 0.062399722635746, 0.1314907670021057, 0.07288065552711487, 0.4124484658241272]]\n",
      "Predicted label: 5\n",
      "\n",
      "Text: 작은 시골집의 다락방에서 발견된 오래된 라디오. 소년이 그것을 켜자, 사라진 조부모의 목소리가 흘러나왔다. 라디오는 시간과 공간을 넘어 메시지를 전달하는 신비한 기계였고, 소년은 그 비밀을 풀기 위해 모험을 시작했다.\n",
      "Scores: [[0.7414906024932861, 0.05947146192193031, 0.014267819002270699, 0.0690639466047287, 0.04026326537132263, 0.07544291764497757]]\n",
      "Predicted label: 0\n",
      "\n",
      "Text: 도시 외곽의 숲속에는 한 번도 본 적 없는 하얀 사슴이 나타났다. 한 소녀가 사슴을 따라 숲 깊은 곳으로 들어가자, 그녀는 마법의 나라로 통하는 문을 발견했다. 그 문은 그녀에게 새로운 삶의 기회를 제시했다.\n",
      "Scores: [[0.9296291470527649, 0.016543328762054443, 0.00371975963935256, 0.025383926928043365, 0.008787712082266808, 0.01593603752553463]]\n",
      "Predicted label: 0\n",
      "\n",
      "Text: 매일 같은 꿈을 꾸는 한 남자는 꿈속에서 매번 같은 목소리를 들었다. '진실을 찾아라.' 어느 날 그는 꿈에서 본 장소를 실제로 발견했고, 그곳에서 자신이 잊고 지냈던 과거의 비밀이 담긴 물건을 발견했다.\n",
      "Scores: [[0.4377574622631073, 0.19976107776165009, 0.04659772664308548, 0.1240486353635788, 0.10073668509721756, 0.09109842032194138]]\n",
      "Predicted label: 0\n",
      "\n",
      "Text: 한 소녀가 공원에서 조그만 상자를 발견했다. 상자 안에는 작은 쪽지가 들어 있었고, '마음을 여는 열쇠를 찾아라'고 적혀 있었다. 그녀는 그 문구를 따라가며, 자신의 삶을 변화시키는 특별한 열쇠를 발견했다.\n",
      "Scores: [[0.5569106340408325, 0.10779895633459091, 0.021225208416581154, 0.11871134489774704, 0.04664618894457817, 0.14870770275592804]]\n",
      "Predicted label: 0\n",
      "\n",
      "Text: 비 오는 날, 우산 없이 걷던 한 남자가 거리에서 빛나는 작은 돌멩이를 발견했다. 그는 무심코 돌을 주웠고, 그 순간 주변의 시간이 멈춘 듯한 경험을 했다. 돌멩이는 시간을 조종할 수 있는 신비한 능력을 가지고 있었다.\n",
      "Scores: [[0.7123385071754456, 0.06592795997858047, 0.015603729523718357, 0.059814196079969406, 0.03660406172275543, 0.10971154272556305]]\n",
      "Predicted label: 0\n",
      "\n",
      "Text: 한 노인이 산책 중 발견한 낡은 손수레에는 ‘마음의 무게를 담습니다’라는 문구가 쓰여 있었다. 호기심에 손수레를 끌고 집으로 돌아온 그는 자신의 지난 슬픔과 기쁨이 그 안에서 빛나는 구슬로 변하는 것을 목격했다.\n",
      "Scores: [[0.15538084506988525, 0.7155598402023315, 0.01045980118215084, 0.054103683680295944, 0.02258169837296009, 0.0419141948223114]]\n",
      "Predicted label: 1\n",
      "\n",
      "Text: 한 마을에 살던 소년은 매일 밤 창문 밖으로 들리는 피아노 소리를 따라가다 숲속에서 황금빛 그랜드 피아노를 발견했다. 피아노를 연주하면 소년의 꿈이 현실처럼 펼쳐지곤 했다.\n",
      "Scores: [[0.8779010772705078, 0.05134968459606171, 0.006277768407016993, 0.027944331988692284, 0.01549743302166462, 0.021029731258749962]]\n",
      "Predicted label: 0\n",
      "\n",
      "Text: 버려진 놀이공원에서 놀던 한 아이가 오래된 회전목마를 돌리자, 그 순간 아이는 과거로 되돌아갔다. 과거의 사람들은 아이를 환영했고, 아이는 그곳에서 자신이 태어나기 전 가족의 이야기를 알게 되었다.\n",
      "Scores: [[0.44356080889701843, 0.2767670452594757, 0.02245519869029522, 0.09087345749139786, 0.05181356146931648, 0.11453000456094742]]\n",
      "Predicted label: 0\n",
      "\n",
      "Text: 매일 밤 하늘에 떠오르는 별 하나가 갑자기 사라졌다. 한 소녀는 사라진 별이 지구 어딘가에 떨어졌다는 소문을 듣고 별을 찾기 위한 여정을 시작했다. 그녀는 별의 잔해 속에서 놀라운 비밀을 발견했다.\n",
      "Scores: [[0.28415513038635254, 0.2300797551870346, 0.06410565972328186, 0.12728610634803772, 0.13453084230422974, 0.15984247624874115]]\n",
      "Predicted label: 0\n",
      "\n",
      "Text: 도서관 지하에서 발견된 낡은 책. 그 책을 펼치면 한 페이지씩 마법의 장면이 살아났다. 하지만 한 번 펼쳐진 장면은 현실에 남아버렸고, 독자는 이를 되돌리기 위해 책의 마지막 페이지를 찾아야 했다.\n",
      "Scores: [[0.1759205311536789, 0.31194770336151123, 0.07891134917736053, 0.09566536545753479, 0.20699506998062134, 0.1305600255727768]]\n",
      "Predicted label: 1\n",
      "\n",
      "Text: 항상 같은 꿈속에 나타나는 하얀 고양이. 꿈속 고양이는 말을 할 줄 알았고, 주인공에게 ‘세 번째 달을 찾아라’는 말을 반복했다. 꿈에서 깨어난 주인공은 그 말의 의미를 찾아 여행을 떠나게 된다.\n",
      "Scores: [[0.35530605912208557, 0.17595915496349335, 0.09426272660493851, 0.10437218099832535, 0.12374088168144226, 0.14635907113552094]]\n",
      "Predicted label: 0\n",
      "\n",
      "Text: 한 외딴 섬에서 발견된 묵직한 나무 상자. 그 상자를 열면 사람마다 다르게 보이는 빛이 뿜어져 나왔다. 어떤 이는 그것을 두려워했고, 어떤 이는 그 빛 속에서 자신의 과거를 보았다.\n",
      "Scores: [[0.29202044010162354, 0.11129669845104218, 0.03901159390807152, 0.08410447835922241, 0.22900931537151337, 0.2445574700832367]]\n",
      "Predicted label: 0\n",
      "\n",
      "Text: 매일 학교 앞 벤치에 앉아 있던 할아버지가 어느 날 갑자기 사라졌다. 그가 앉아 있던 자리에는 ‘고마웠다’는 쪽지가 남아 있었다. 쪽지를 본 주인공은 할아버지가 남긴 작은 단서를 따라가며 그의 이야기를 알게 된다.\n",
      "Scores: [[0.5529625415802002, 0.1784839779138565, 0.015459451824426651, 0.11191307008266449, 0.03550489991903305, 0.10567604005336761]]\n",
      "Predicted label: 0\n",
      "\n",
      "Text: 우연히 들른 골동품 가게에서 낡은 시계를 구매한 소년. 시계를 돌릴 때마다 10초 전으로 돌아가는 신비한 능력이 있었다. 하지만 시계를 사용할수록 점점 미래를 잃어가는 것을 깨닫게 되었다.\n",
      "Scores: [[0.4327612519264221, 0.13065187633037567, 0.03870652988553047, 0.09402661770582199, 0.12613902986049652, 0.17771467566490173]]\n",
      "Predicted label: 0\n",
      "\n",
      "Text: 한적한 마을의 우체통에 이상한 편지가 배달되기 시작했다. 편지에는 모두 같은 문장이 적혀 있었다. '내일을 잊지 말라.' 마을 사람들은 이 편지의 의미를 추적하며 뜻밖의 비밀을 발견했다.\n",
      "Scores: [[0.3035534918308258, 0.106341153383255, 0.04326050728559494, 0.10277212411165237, 0.11604318022727966, 0.3280295729637146]]\n",
      "Predicted label: 5\n",
      "\n",
      "Text: 매년 첫눈이 내리는 날이면 나타나는 신비한 꽃이 있었다. 전설에 따르면 이 꽃을 손에 쥔 사람은 가장 간절히 바라는 소원이 이루어진다고 했다. 하지만 꽃을 찾으려면 가장 소중한 것을 포기해야 했다.\n",
      "Scores: [[0.4312061071395874, 0.30096927285194397, 0.028826899826526642, 0.12404163926839828, 0.06168310344219208, 0.05327294021844864]]\n",
      "Predicted label: 0\n",
      "\n",
      "Text: 도시 중심에 있는 오래된 시계탑이 정각을 알릴 때마다 한 소녀의 일기가 공중에서 떨어졌다. 일기에는 소녀가 미래에 겪을 사건들이 예언처럼 적혀 있었고, 그녀는 이를 바꾸기 위해 시계탑의 비밀을 찾아 나섰다.\n",
      "Scores: [[0.16402171552181244, 0.20561441779136658, 0.07254084944725037, 0.1229524239897728, 0.16613653302192688, 0.26873403787612915]]\n",
      "Predicted label: 5\n",
      "\n",
      "Text: 어느 날 바닷가에서 발견된 고대의 나침반은 이상하게도 북쪽이 아닌 하늘을 가리켰다. 이를 이상하게 여긴 소년은 나침반이 가리키는 곳으로 모험을 떠났고, 하늘 너머의 숨겨진 도시를 발견하게 되었다.\n",
      "Scores: [[0.03390204533934593, 0.027417801320552826, 0.021868744865059853, 0.06934590637683868, 0.026800522580742836, 0.8206649422645569]]\n",
      "Predicted label: 5\n",
      "\n",
      "Text: 한 마을의 거울 가게에는 자신이 가진 가장 큰 두려움을 비추는 거울이 있었다. 주인공은 거울 속에서 자신이 가진 용기와 두려움을 동시에 발견하며 진정한 자신을 마주하게 된다.\n",
      "Scores: [[0.8044798374176025, 0.04777319356799126, 0.00965079851448536, 0.050606247037649155, 0.03186860680580139, 0.055621352046728134]]\n",
      "Predicted label: 0\n",
      "\n",
      "Text: 정체불명의 우편물이 매주 화요일마다 주인공의 문 앞에 놓여 있었다. 편지 속에는 다른 사람의 기억이 담긴 사진과 문구가 들어 있었고, 주인공은 이를 통해 주변 사람들의 숨겨진 진실을 알게 되었다.\n",
      "Scores: [[0.24402834475040436, 0.09296266734600067, 0.030963174998760223, 0.11875294893980026, 0.07225814461708069, 0.4410346448421478]]\n",
      "Predicted label: 5\n",
      "\n",
      "Text: 매일 밤 같은 꿈을 꾸던 소녀는 꿈속에서 자신이 살아가는 세상이 환영이라는 사실을 깨달았다. 그녀는 꿈속의 지도를 따라 현실을 벗어나기 위한 여정을 시작한다.\n",
      "Scores: [[0.4319758117198944, 0.15474703907966614, 0.03273511305451393, 0.1373334676027298, 0.06160480156540871, 0.18160380423069]]\n",
      "Predicted label: 0\n",
      "\n",
      "Text: 도시 한복판에서 발견된 낡은 우물에서는 매달 보름달이 뜨는 날마다 은빛 물이 솟아올랐다. 전설에 따르면 이 물을 마시면 자신의 잊힌 기억을 되찾을 수 있었다.\n",
      "Scores: [[0.951840877532959, 0.01755477674305439, 0.003144723828881979, 0.01443623099476099, 0.006223220378160477, 0.006800131872296333]]\n",
      "Predicted label: 0\n",
      "\n",
      "Text: 한 남자가 매일 다니는 골목길에 생겨난 낯선 문. 문을 열 때마다 그가 경험하지 않은 과거의 장면이 펼쳐졌다. 남자는 이 장면들이 자신의 인생에 중요한 의미를 가지고 있다는 것을 알게 되었다.\n",
      "Scores: [[0.42850133776664734, 0.09801100194454193, 0.026930255815386772, 0.09805946052074432, 0.08044090867042542, 0.26805710792541504]]\n",
      "Predicted label: 0\n",
      "\n",
      "Text: 작은 시골 마을의 오래된 나무에는 세상 모든 언어로 쓰인 글자들이 새겨져 있었다. 마을 사람들은 나무가 가진 신비를 두려워했지만, 한 아이는 나무를 통해 미래의 메시지를 해독하기 시작했다.\n",
      "Scores: [[0.8991230726242065, 0.01820751279592514, 0.005863890517503023, 0.03080725111067295, 0.020189017057418823, 0.025809230282902718]]\n",
      "Predicted label: 0\n",
      "\n",
      "Text: 도시 외곽의 고요한 호수에는 달빛이 비칠 때만 나타나는 보트가 있었다. 보트에 타면 시간의 흐름이 느려지며 과거의 사건들을 직접 관찰할 수 있었다. 하지만 모든 것은 단 한 번만 가능했다.\n",
      "Scores: [[0.60737544298172, 0.1495829075574875, 0.02424631640315056, 0.05496063455939293, 0.08919315785169601, 0.07464156299829483]]\n",
      "Predicted label: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for item in data:\n",
    "    inputs = tokenizer(item['content'], return_tensors=\"pt\", padding=True, truncation=True, max_length=128)\n",
    "    inputs = {key: value.to(device) for key, value in inputs.items()}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        scores = torch.softmax(outputs.logits, dim=1)  # 감성 확률 계산\n",
    "        predicted_label = torch.argmax(scores, dim=1).item()\n",
    "\n",
    "        item['sentiment'] = predicted_label\n",
    "\n",
    "    print(f\"Text: {item['content']}\")\n",
    "    print(f\"Scores: {scores.tolist()}\")\n",
    "    print(f\"Predicted label: {predicted_label}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과 출력\n",
    "output_file = './results/using_test_data.json'\n",
    "with open(output_file, 'w', encoding='utf-8') as json_f:\n",
    "    json.dump(data, json_f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ailab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
